# Language modeling Project
Final project of the course Natural Language Understanding A.Y. 2021/2022. The aim of the project was to implement a language model using a recurrent neural network to reach a perplexity lower than 90.7 on the Penn Treebank dataset.

## Code
The code can be found [here](./Guidolin_Davide_232224.ipynb) or you can open it directly on Google Colab:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Davide-Guidolin/Language_modeling_NLU_project/blob/main/Guidolin_Davide_232224.ipynb)

## Report
The report containing a description of the work done and the obtained results can be found [here](./Report.pdf).

## Models
All the training logs and the trained models can be found on [this](https://drive.google.com/drive/folders/1VcUYj3w1DzH8oJ3VYAi5eQUySJS5bhW5?usp=sharing) Drive folder.

## Dataset
The Penn Treebank dataset, that was used to train and test the models, will be downloaded and preprocessed automatically in the notebook.
